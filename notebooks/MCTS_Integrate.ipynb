{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccadf0ce-96ab-4cae-8d9f-2346d0ade148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5c6f8a-fe9f-49e3-bb5d-ee5c499c2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports complete!\n",
      "🎮 CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ Imports complete!\")\n",
    "print(f\"🎮 CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50d60f3-1179-4d78-89bc-59140d486858",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReasoningNode:\n",
    "    \"\"\"MCTS Node representing one step in reasoning chain\"\"\"\n",
    "    reasoning_step: str\n",
    "    confidence_score: float = 0.0\n",
    "    visit_count: int = 0\n",
    "    value_sum: float = 0.0\n",
    "    children: List['ReasoningNode'] = field(default_factory=list)\n",
    "    parent: Optional['ReasoningNode'] = None\n",
    "    is_terminal: bool = False\n",
    "    \n",
    "    def ucb_score(self, exploration_weight: float = 1.4) -> float:\n",
    "        \"\"\"Calculate UCB (Upper Confidence Bound) score for node selection\"\"\"\n",
    "        if self.visit_count == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        exploitation = self.value_sum / self.visit_count\n",
    "        if self.parent and self.parent.visit_count > 0:\n",
    "            exploration = math.sqrt(math.log(self.parent.visit_count) / self.visit_count)\n",
    "        else:\n",
    "            exploration = 0\n",
    "        return exploitation + exploration_weight * exploration\n",
    "    \n",
    "    def is_fully_expanded(self, max_children: int = 3) -> bool:  # Reduced from 5\n",
    "        \"\"\"Check if node has been fully expanded\"\"\"\n",
    "        return len(self.children) >= max_children or self.is_terminal\n",
    "\n",
    "class MCTSReasoningEngine:\n",
    "    \"\"\"MCTS-based reasoning chain generator for academic visual reasoning\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"microsoft/DialoGPT-medium\", use_lightweight: bool = True):\n",
    "        logger.info(f\"Initializing MCTS Engine with model: {model_name}\")\n",
    "        \n",
    "        # Use lighter model and configuration for stability\n",
    "        self.model_name = model_name\n",
    "        self.use_lightweight = use_lightweight\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Initialize model with better memory management\n",
    "        self._initialize_model()\n",
    "        \n",
    "        # Reduced MCTS parameters for stability\n",
    "        self.max_iterations = 20  # Reduced from 50\n",
    "        self.max_depth = 5       # Reduced from 8\n",
    "        self.exploration_weight = 1.4\n",
    "        \n",
    "        # Pre-defined reasoning templates (no LLM needed)\n",
    "        self.reasoning_templates = {\n",
    "            \"professional_entity_location\": [\n",
    "                \"Analyze the professional context and domain\",\n",
    "                \"Identify key organizations or institutions mentioned\", \n",
    "                \"Match entity characteristics with domain knowledge\",\n",
    "                \"Verify entity relevance to the scenario\"\n",
    "            ],\n",
    "            \"multimodal_temporal_reasoning\": [\n",
    "                \"Identify temporal markers and sequences\",\n",
    "                \"Analyze chronological relationships\",\n",
    "                \"Connect timing with context\",\n",
    "                \"Validate temporal consistency\"\n",
    "            ],\n",
    "            \"cross_subgraph_role_reasoning\": [\n",
    "                \"Identify system components\", \n",
    "                \"Analyze component relationships\",\n",
    "                \"Understand component roles\",\n",
    "                \"Map system interactions\"\n",
    "            ],\n",
    "            \"causal_mechanism_reasoning\": [\n",
    "                \"Identify cause-effect relationships\",\n",
    "                \"Trace causal pathways\",\n",
    "                \"Analyze mechanisms\",\n",
    "                \"Verify causal logic\"\n",
    "            ],\n",
    "            \"methodological_technical_reasoning\": [\n",
    "                \"Identify technical methods\",\n",
    "                \"Analyze method characteristics\",\n",
    "                \"Evaluate method appropriateness\",\n",
    "                \"Validate technical accuracy\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _initialize_model(self):\n",
    "        \"\"\"Initialize model with proper memory management\"\"\"\n",
    "        try:\n",
    "            if self.use_lightweight:\n",
    "                # Use a more stable, lighter approach\n",
    "                self.tokenizer = None\n",
    "                self.model = None\n",
    "                self.reasoning_generator = None\n",
    "                logger.info(\"Using lightweight mode - no LLM loading\")\n",
    "            else:\n",
    "                # Load model with better configuration\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    padding_side='left',\n",
    "                    cache_dir='./model_cache'\n",
    "                )\n",
    "                \n",
    "                self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "                    low_cpu_mem_usage=True,\n",
    "                    cache_dir='./model_cache',\n",
    "                    device_map=\"auto\" if self.device == \"cuda\" else None\n",
    "                )\n",
    "                \n",
    "                if self.tokenizer.pad_token is None:\n",
    "                    self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "                \n",
    "                self.reasoning_generator = pipeline(\n",
    "                    \"text-generation\",\n",
    "                    model=self.model,\n",
    "                    tokenizer=self.tokenizer,\n",
    "                    max_new_tokens=50,  # Reduced\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    device=0 if self.device == \"cuda\" else -1,\n",
    "                    batch_size=1\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"Model loaded successfully on {self.device}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            logger.info(\"Falling back to lightweight mode\")\n",
    "            self.use_lightweight = True\n",
    "            self.reasoning_generator = None\n",
    "\n",
    "    @contextmanager\n",
    "    def memory_cleanup(self):\n",
    "        \"\"\"Context manager for memory cleanup\"\"\"\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    def generate_thought_chain(self, question_data: Dict) -> Dict:\n",
    "        \"\"\"Main entry point: Generate reasoning chain for a question using MCTS\"\"\"\n",
    "        \n",
    "        with self.memory_cleanup():\n",
    "            logger.info(f\"Generating chain for: {question_data.get('reasoning_type', 'unknown')}\")\n",
    "            \n",
    "            # Initialize root node\n",
    "            root = ReasoningNode(\n",
    "                reasoning_step=f\"Question: {question_data['gapped_text']}\",\n",
    "                confidence_score=1.0\n",
    "            )\n",
    "            \n",
    "            # Run MCTS iterations with progress tracking\n",
    "            for iteration in range(self.max_iterations):\n",
    "                if iteration % 5 == 0:\n",
    "                    logger.debug(f\"MCTS iteration {iteration}/{self.max_iterations}\")\n",
    "                \n",
    "                try:\n",
    "                    # (a) Selection: Find best node to expand\n",
    "                    selected_node = self.select_node(root)\n",
    "                    \n",
    "                    # (b) Expansion: Add new reasoning step\n",
    "                    if not selected_node.is_fully_expanded():\n",
    "                        new_node = self.expand_node(selected_node, question_data)\n",
    "                        if new_node:\n",
    "                            selected_node = new_node\n",
    "                    \n",
    "                    # (c) Simulation: Complete reasoning chain and evaluate\n",
    "                    simulation_value = self.simulate_reasoning(selected_node, question_data)\n",
    "                    \n",
    "                    # (d) Backpropagation: Update node values\n",
    "                    self.backpropagate(selected_node, simulation_value)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Error in MCTS iteration {iteration}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Extract best reasoning chain\n",
    "            best_chain = self.extract_best_chain(root)\n",
    "            \n",
    "            return {\n",
    "                \"question_id\": question_data.get(\"question_id\", f\"q_{random.randint(1000, 9999)}\"),\n",
    "                \"reasoning_type\": question_data[\"reasoning_type\"],\n",
    "                \"question\": question_data[\"gapped_text\"],\n",
    "                \"answers\": question_data[\"answers\"],\n",
    "                \"thought_chain\": best_chain,\n",
    "                \"reasoning_quality_score\": self.evaluate_chain_quality(best_chain, question_data),\n",
    "                \"mcts_iterations\": self.max_iterations,\n",
    "                \"mcts_exploration_depth\": len(best_chain)\n",
    "            }\n",
    "\n",
    "    def select_node(self, root: ReasoningNode) -> ReasoningNode:\n",
    "        \"\"\"(a) Selection: Select most promising node using UCB\"\"\"\n",
    "        current = root\n",
    "        depth = 0\n",
    "        \n",
    "        while current.children and current.is_fully_expanded() and depth < self.max_depth:\n",
    "            # Select child with highest UCB score\n",
    "            try:\n",
    "                best_child = max(current.children, key=lambda child: child.ucb_score(self.exploration_weight))\n",
    "                current = best_child\n",
    "                depth += 1\n",
    "            except ValueError:\n",
    "                break\n",
    "        \n",
    "        return current\n",
    "\n",
    "    def expand_node(self, node: ReasoningNode, question_data: Dict) -> Optional[ReasoningNode]:\n",
    "        \"\"\"(b) Expansion: Add new reasoning step as child node\"\"\"\n",
    "        \n",
    "        # Don't expand beyond max depth\n",
    "        current_depth = self.get_node_depth(node)\n",
    "        if current_depth >= self.max_depth:\n",
    "            node.is_terminal = True\n",
    "            return None\n",
    "        \n",
    "        # Generate next reasoning step\n",
    "        reasoning_type = question_data[\"reasoning_type\"]\n",
    "        current_chain = self.get_chain_to_node(node)\n",
    "        \n",
    "        next_step = self.generate_next_reasoning_step_template(\n",
    "            current_chain, \n",
    "            question_data, \n",
    "            reasoning_type\n",
    "        )\n",
    "        \n",
    "        if next_step:\n",
    "            # Create new child node\n",
    "            child_node = ReasoningNode(\n",
    "                reasoning_step=next_step,\n",
    "                parent=node,\n",
    "                is_terminal=(current_depth >= self.max_depth - 1)\n",
    "            )\n",
    "            \n",
    "            node.children.append(child_node)\n",
    "            return child_node\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def generate_next_reasoning_step_template(self, current_chain: List[str], question_data: Dict, reasoning_type: str) -> str:\n",
    "        \"\"\"Generate next reasoning step using templates (no LLM required)\"\"\"\n",
    "        \n",
    "        # Get template steps for this reasoning type\n",
    "        template_steps = self.reasoning_templates.get(reasoning_type, [])\n",
    "        current_step_index = len(current_chain) - 1  # Subtract 1 for initial question\n",
    "        \n",
    "        if current_step_index < len(template_steps):\n",
    "            # Use template-based reasoning\n",
    "            template_step = template_steps[current_step_index]\n",
    "            \n",
    "            # Customize template with question context\n",
    "            customized_step = self.customize_reasoning_step(\n",
    "                template_step, \n",
    "                question_data\n",
    "            )\n",
    "            \n",
    "            return customized_step\n",
    "        else:\n",
    "            # Generate fallback reasoning step\n",
    "            return self.generate_fallback_reasoning_step(current_chain, question_data)\n",
    "\n",
    "    def customize_reasoning_step(self, template_step: str, question_data: Dict) -> str:\n",
    "        \"\"\"Customize template reasoning step with question-specific details\"\"\"\n",
    "        \n",
    "        reasoning_type = question_data[\"reasoning_type\"]\n",
    "        answers = question_data.get(\"answers\", [])\n",
    "        \n",
    "        # Customize based on reasoning type\n",
    "        if reasoning_type == \"professional_entity_location\":\n",
    "            if \"organizations\" in template_step.lower():\n",
    "                return f\"Consider organizations like {', '.join(answers[:2])} that are relevant to this domain\"\n",
    "        \n",
    "        elif reasoning_type == \"methodological_technical_reasoning\":\n",
    "            if \"technical\" in template_step.lower():\n",
    "                return f\"Analyze the technical methods: {', '.join(answers[:2])} and their applications\"\n",
    "        \n",
    "        elif reasoning_type == \"multimodal_temporal_reasoning\":\n",
    "            if \"temporal\" in template_step.lower():\n",
    "                return f\"Examine the time-related information: {', '.join(answers[:2])}\"\n",
    "        \n",
    "        elif reasoning_type == \"causal_mechanism_reasoning\":\n",
    "            if \"cause\" in template_step.lower():\n",
    "                return f\"Trace how {answers[0] if answers else 'input'} leads to the described outcome\"\n",
    "        \n",
    "        elif reasoning_type == \"cross_subgraph_role_reasoning\":\n",
    "            if \"components\" in template_step.lower():\n",
    "                return f\"Analyze the structural elements: {', '.join(answers[:2])} and their relationships\"\n",
    "        \n",
    "        return template_step\n",
    "\n",
    "    def generate_fallback_reasoning_step(self, current_chain: List[str], question_data: Dict) -> str:\n",
    "        \"\"\"Generate fallback reasoning step without LLM\"\"\"\n",
    "        \n",
    "        fallback_steps = [\n",
    "            \"Review the established context and relationships\",\n",
    "            \"Validate the logical consistency of the reasoning\",\n",
    "            \"Consider alternative explanations or approaches\",\n",
    "            \"Synthesize the information to reach a conclusion\"\n",
    "        ]\n",
    "        \n",
    "        step_index = (len(current_chain) - 1) % len(fallback_steps)\n",
    "        return fallback_steps[step_index]\n",
    "\n",
    "    def simulate_reasoning(self, node: ReasoningNode, question_data: Dict) -> float:\n",
    "        \"\"\"(c) Simulation: Complete reasoning chain and evaluate quality\"\"\"\n",
    "        \n",
    "        # Get current chain\n",
    "        current_chain = self.get_chain_to_node(node)\n",
    "        \n",
    "        # If terminal node, evaluate current chain\n",
    "        if node.is_terminal or len(current_chain) >= self.max_depth:\n",
    "            return self.evaluate_chain_quality(current_chain, question_data)\n",
    "        \n",
    "        # Otherwise, simulate completion with template steps\n",
    "        simulated_chain = current_chain.copy()\n",
    "        reasoning_type = question_data[\"reasoning_type\"]\n",
    "        \n",
    "        while len(simulated_chain) < self.max_depth:\n",
    "            # Add a simulated reasoning step\n",
    "            next_step = self.generate_next_reasoning_step_template(\n",
    "                simulated_chain, \n",
    "                question_data, \n",
    "                reasoning_type\n",
    "            )\n",
    "            simulated_chain.append(next_step)\n",
    "            \n",
    "            # Random chance to terminate early\n",
    "            if random.random() < 0.4:  # Increased chance for shorter chains\n",
    "                break\n",
    "        \n",
    "        return self.evaluate_chain_quality(simulated_chain, question_data)\n",
    "\n",
    "    def evaluate_chain_quality(self, reasoning_chain: List[str], question_data: Dict) -> float:\n",
    "        \"\"\"Evaluate quality of reasoning chain (0-1 score)\"\"\"\n",
    "        \n",
    "        if len(reasoning_chain) <= 1:  # Just the question\n",
    "            return 0.1\n",
    "        \n",
    "        score = 0.0\n",
    "        reasoning_steps = reasoning_chain[1:]  # Exclude initial question\n",
    "        \n",
    "        # Factor 1: Chain length (optimal around 3-4 steps)\n",
    "        optimal_length = 4\n",
    "        length_score = 1.0 - abs(len(reasoning_steps) - optimal_length) / optimal_length\n",
    "        length_score = max(0, min(1, length_score))\n",
    "        score += 0.25 * length_score\n",
    "        \n",
    "        # Factor 2: Reasoning type alignment\n",
    "        reasoning_type = question_data[\"reasoning_type\"]\n",
    "        template_steps = self.reasoning_templates.get(reasoning_type, [])\n",
    "        \n",
    "        alignment_score = 0.0\n",
    "        for i, step in enumerate(reasoning_steps):\n",
    "            if i < len(template_steps):\n",
    "                # Check if step follows template logic\n",
    "                template_keywords = template_steps[i].lower().split()\n",
    "                step_keywords = step.lower().split()\n",
    "                overlap = len(set(template_keywords) & set(step_keywords))\n",
    "                alignment_score += overlap / max(len(template_keywords), 1)\n",
    "        \n",
    "        if len(reasoning_steps) > 0:\n",
    "            alignment_score /= len(reasoning_steps)\n",
    "        score += 0.35 * alignment_score\n",
    "        \n",
    "        # Factor 3: Answer relevance\n",
    "        answers = question_data.get(\"answers\", [])\n",
    "        answer_mentions = 0\n",
    "        for answer in answers:\n",
    "            for step in reasoning_steps:\n",
    "                if answer.lower() in step.lower():\n",
    "                    answer_mentions += 1\n",
    "                    break\n",
    "        \n",
    "        answer_relevance = answer_mentions / max(len(answers), 1)\n",
    "        score += 0.3 * answer_relevance\n",
    "        \n",
    "        # Factor 4: Logical progression\n",
    "        progression_score = 0.8  # Default good progression\n",
    "        score += 0.1 * progression_score\n",
    "        \n",
    "        return min(1.0, score)\n",
    "\n",
    "    def backpropagate(self, node: ReasoningNode, value: float):\n",
    "        \"\"\"(d) Backpropagation: Update node statistics\"\"\"\n",
    "        \n",
    "        current = node\n",
    "        while current is not None:\n",
    "            current.visit_count += 1\n",
    "            current.value_sum += value\n",
    "            current = current.parent\n",
    "\n",
    "    def extract_best_chain(self, root: ReasoningNode) -> List[str]:\n",
    "        \"\"\"Extract the best reasoning chain from MCTS tree\"\"\"\n",
    "        \n",
    "        chain = [root.reasoning_step]\n",
    "        current = root\n",
    "        \n",
    "        while current.children:\n",
    "            # Select child with highest average value\n",
    "            best_child = max(\n",
    "                current.children, \n",
    "                key=lambda child: child.value_sum / max(child.visit_count, 1)\n",
    "            )\n",
    "            chain.append(best_child.reasoning_step)\n",
    "            current = best_child\n",
    "        \n",
    "        return chain\n",
    "\n",
    "    def get_chain_to_node(self, node: ReasoningNode) -> List[str]:\n",
    "        \"\"\"Get reasoning chain from root to given node\"\"\"\n",
    "        chain = []\n",
    "        current = node\n",
    "        \n",
    "        while current is not None:\n",
    "            chain.insert(0, current.reasoning_step)\n",
    "            current = current.parent\n",
    "        \n",
    "        return chain\n",
    "\n",
    "    def get_node_depth(self, node: ReasoningNode) -> int:\n",
    "        \"\"\"Get depth of node in tree\"\"\"\n",
    "        depth = 0\n",
    "        current = node.parent\n",
    "        \n",
    "        while current is not None:\n",
    "            depth += 1\n",
    "            current = current.parent\n",
    "        \n",
    "        return depth\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up model and free memory\"\"\"\n",
    "        if hasattr(self, 'model') and self.model:\n",
    "            del self.model\n",
    "        if hasattr(self, 'tokenizer') and self.tokenizer:\n",
    "            del self.tokenizer\n",
    "        if hasattr(self, 'reasoning_generator') and self.reasoning_generator:\n",
    "            del self.reasoning_generator\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        logger.info(\"Model cleanup completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3ff90a-79e7-4508-b3db-e10613036f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_jupyter(input_path: str, output_path: str, batch_size: int = 5):\n",
    "    \n",
    "    # Initialize engine\n",
    "    mcts_engine = MCTSReasoningEngine(use_lightweight=True)\n",
    "    \n",
    "    # For specific domains: Custom models\n",
    "    #engine = MCTSReasoningEngine(use_lightweight=False, model_name=\"microsoft/BioGPT\")\n",
    "    try:\n",
    "        # Load questions\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            questions = json.load(f)\n",
    "        \n",
    "        total_questions = len(questions)\n",
    "        print(f\"🌳 Processing {total_questions} questions\")\n",
    "        print(f\"📦 Batch size: {batch_size}\")\n",
    "        print(f\"⏱️  Estimated time: {total_questions * 2 / 60:.1f} minutes\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        sci_reason_dataset = []\n",
    "        batch_stats = []\n",
    "        \n",
    "        # Process in batches\n",
    "        for batch_start in range(0, total_questions, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, total_questions)\n",
    "            batch_questions = questions[batch_start:batch_end]\n",
    "            batch_num = batch_start // batch_size + 1\n",
    "            total_batches = (total_questions - 1) // batch_size + 1\n",
    "            \n",
    "            print(f\"\\n🔄 Batch {batch_num}/{total_batches} (Questions {batch_start+1}-{batch_end})\")\n",
    "            \n",
    "            batch_start_time = time.time()\n",
    "            batch_results = []\n",
    "            \n",
    "            for i, question in enumerate(batch_questions):\n",
    "                question_start = time.time()\n",
    "                \n",
    "                try:\n",
    "                    result = mcts_engine.generate_thought_chain(question)\n",
    "                    batch_results.append(result)\n",
    "                    sci_reason_dataset.append(result)\n",
    "                    \n",
    "                    question_time = time.time() - question_start\n",
    "                    print(f\"  ✅ Q{batch_start+i+1}: {result['reasoning_type'][:20]}... \"\n",
    "                          f\"({len(result['thought_chain'])} steps, \"\n",
    "                          f\"score: {result['reasoning_quality_score']:.3f}, \"\n",
    "                          f\"{question_time:.1f}s)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ❌ Q{batch_start+i+1}: Error - {str(e)[:50]}...\")\n",
    "                    continue\n",
    "            \n",
    "            # Batch statistics\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            avg_quality = sum(r['reasoning_quality_score'] for r in batch_results) / max(len(batch_results), 1)\n",
    "            \n",
    "            batch_stats.append({\n",
    "                'batch': batch_num,\n",
    "                'questions': len(batch_results),\n",
    "                'avg_quality': avg_quality,\n",
    "                'time': batch_time\n",
    "            })\n",
    "            \n",
    "            print(f\"  📊 Batch complete: {len(batch_results)}/{len(batch_questions)} success, \"\n",
    "                  f\"avg quality: {avg_quality:.3f}, time: {batch_time:.1f}s\")\n",
    "            \n",
    "            # Memory cleanup\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Save intermediate results every 3 batches\n",
    "            if batch_num % 3 == 0:\n",
    "                temp_file = output_path.replace('.json', f'_checkpoint_batch_{batch_num}.json')\n",
    "                with open(temp_file, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(sci_reason_dataset, f, ensure_ascii=False, indent=2)\n",
    "                print(f\"  💾 Checkpoint saved: {temp_file}\")\n",
    "        \n",
    "        # Save final results\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(sci_reason_dataset, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # Final statistics\n",
    "        print(f\"\\n🎉 PROCESSING COMPLETE!\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"✅ Successfully processed: {len(sci_reason_dataset)}/{total_questions}\")\n",
    "        print(f\"📁 Output saved to: {output_path}\")\n",
    "        \n",
    "        if sci_reason_dataset:\n",
    "            avg_quality = sum(item['reasoning_quality_score'] for item in sci_reason_dataset) / len(sci_reason_dataset)\n",
    "            avg_chain_length = sum(len(item['thought_chain']) for item in sci_reason_dataset) / len(sci_reason_dataset)\n",
    "            \n",
    "            print(f\"📊 Average Quality Score: {avg_quality:.3f}\")\n",
    "            print(f\"📏 Average Chain Length: {avg_chain_length:.1f} steps\")\n",
    "            \n",
    "            # Reasoning type breakdown\n",
    "            by_type = {}\n",
    "            for item in sci_reason_dataset:\n",
    "                rtype = item['reasoning_type']\n",
    "                by_type[rtype] = by_type.get(rtype, 0) + 1\n",
    "            \n",
    "            print(f\"\\n📋 Results by Reasoning Type:\")\n",
    "            for rtype, count in sorted(by_type.items()):\n",
    "                print(f\"   {rtype}: {count}\")\n",
    "        \n",
    "        return sci_reason_dataset, batch_stats\n",
    "        \n",
    "    finally:\n",
    "        mcts_engine.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f8a8db0-9436-4f4e-8062-fac3beb4283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_test():\n",
    "    \"\"\"Test with a few questions first\"\"\"\n",
    "    \n",
    "    print(\"🧪 Running Quick Test\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Test questions\n",
    "    test_questions = [\n",
    "        {\n",
    "            \"reasoning_type\": \"methodological_technical_reasoning\",\n",
    "            \"gapped_text\": \"The study utilizes ______1______ and ______2______ models\",\n",
    "            \"answers\": [\"Random Forest\", \"LSTM\"],\n",
    "            \"question_id\": \"test_001\"\n",
    "        },\n",
    "        {\n",
    "            \"reasoning_type\": \"causal_mechanism_reasoning\", \n",
    "            \"gapped_text\": \"The ______1______ leads to ______2______ in the system\",\n",
    "            \"answers\": [\"input signal\", \"output response\"],\n",
    "            \"question_id\": \"test_002\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    mcts_engine = MCTSReasoningEngine(use_lightweight=True)\n",
    "    \n",
    "    try:\n",
    "        for i, question in enumerate(test_questions, 1):\n",
    "            print(f\"\\n🔍 Test {i}:\")\n",
    "            result = mcts_engine.generate_thought_chain(question)\n",
    "            print(f\"   Type: {result['reasoning_type']}\")\n",
    "            print(f\"   Quality: {result['reasoning_quality_score']:.3f}\")\n",
    "            print(f\"   Steps: {len(result['thought_chain'])}\")\n",
    "            \n",
    "        print(\"\\n✅ Quick test successful! Ready for full processing.\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Test failed: {e}\")\n",
    "        return False\n",
    "        \n",
    "    finally:\n",
    "        mcts_engine.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aafe37dc-e4e2-4141-bb6f-1dc7060789a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress(batch_stats):\n",
    "    \"\"\"Plot processing progress\"\"\"\n",
    "    \n",
    "    if not batch_stats:\n",
    "        return\n",
    "    \n",
    "    batches = [s['batch'] for s in batch_stats]\n",
    "    qualities = [s['avg_quality'] for s in batch_stats]\n",
    "    times = [s['time'] for s in batch_stats]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Quality over time\n",
    "    ax1.plot(batches, qualities, 'b-o', linewidth=2, markersize=6)\n",
    "    ax1.set_xlabel('Batch Number')\n",
    "    ax1.set_ylabel('Average Quality Score')\n",
    "    ax1.set_title('Reasoning Quality Over Time')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Processing time per batch\n",
    "    ax2.bar(batches, times, color='green', alpha=0.7)\n",
    "    ax2.set_xlabel('Batch Number') \n",
    "    ax2.set_ylabel('Processing Time (seconds)')\n",
    "    ax2.set_title('Processing Time per Batch')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ea6e9eb-4cbb-46e3-b6f6-667ca48a0d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 MCTS Reasoning Pipeline - Jupyter Edition\n",
      "==================================================\n",
      "📁 Input: output/stage2_gap_questions.json\n",
      "📁 Output: output/sci_reason_dataset.json\n",
      "📦 Batch Size: 5\n",
      "✅ Input file found!\n",
      "📊 17 questions found\n",
      "⏱️  Estimated time: 0.6 minutes\n",
      "\n",
      "==================================================\n",
      "📋 EXECUTION STEPS:\n",
      "1. Run quick_test() to verify setup\n",
      "2. Run process_dataset_jupyter() for full processing\n",
      "3. Use plot_progress() to visualize results\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"output/stage2_gap_questions.json\"\n",
    "OUTPUT_FILE = \"output/sci_reason_dataset.json\"\n",
    "BATCH_SIZE = 5  # Conservative for Jupyter\n",
    "\n",
    "print(\"🚀 MCTS Reasoning Pipeline - Jupyter Edition\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📁 Input: {INPUT_FILE}\")\n",
    "print(f\"📁 Output: {OUTPUT_FILE}\")\n",
    "print(f\"📦 Batch Size: {BATCH_SIZE}\")\n",
    "\n",
    "# Check if input exists\n",
    "if os.path.exists(INPUT_FILE):\n",
    "    print(f\"✅ Input file found!\")\n",
    "    \n",
    "    # Estimate processing time\n",
    "    with open(INPUT_FILE, 'r') as f:\n",
    "        questions = json.load(f)\n",
    "    \n",
    "    estimated_minutes = len(questions) * 2 / 60\n",
    "    print(f\"📊 {len(questions)} questions found\")\n",
    "    print(f\"⏱️  Estimated time: {estimated_minutes:.1f} minutes\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Input file not found: {INPUT_FILE}\")\n",
    "    print(\"Please ensure your Stage 2 output exists.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"📋 EXECUTION STEPS:\")\n",
    "print(\"1. Run quick_test() to verify setup\")\n",
    "print(\"2. Run process_dataset_jupyter() for full processing\")  \n",
    "print(\"3. Use plot_progress() to visualize results\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd1a484-f795-424f-977a-3d372a0b570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing MCTS Engine with model: microsoft/DialoGPT-medium\n",
      "INFO:__main__:Using lightweight mode - no LLM loading\n",
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n",
      "INFO:__main__:Generating chain for: causal_mechanism_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Running Quick Test\n",
      "==============================\n",
      "\n",
      "🔍 Test 1:\n",
      "   Type: methodological_technical_reasoning\n",
      "   Quality: 0.840\n",
      "   Steps: 4\n",
      "\n",
      "🔍 Test 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model cleanup completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type: causal_mechanism_reasoning\n",
      "   Quality: 0.651\n",
      "   Steps: 4\n",
      "\n",
      "✅ Quick test successful! Ready for full processing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b13aac5-23ee-45e2-a4fd-d694717d8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing MCTS Engine with model: microsoft/DialoGPT-medium\n",
      "INFO:__main__:Using lightweight mode - no LLM loading\n",
      "INFO:__main__:Generating chain for: professional_entity_location\n",
      "INFO:__main__:Generating chain for: multimodal_temporal_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌳 Processing 17 questions\n",
      "📦 Batch size: 5\n",
      "⏱️  Estimated time: 0.6 minutes\n",
      "==================================================\n",
      "\n",
      "🔄 Batch 1/4 (Questions 1-5)\n",
      "  ✅ Q1: professional_entity_... (4 steps, score: 0.820, 0.4s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: cross_subgraph_role_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q2: multimodal_temporal_... (4 steps, score: 0.701, 0.3s)\n",
      "  ✅ Q3: cross_subgraph_role_... (4 steps, score: 0.801, 0.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: causal_mechanism_reasoning\n",
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q4: causal_mechanism_rea... (4 steps, score: 0.651, 0.3s)\n",
      "  ✅ Q5: methodological_techn... (4 steps, score: 0.740, 0.4s)\n",
      "  📊 Batch complete: 5/5 success, avg quality: 0.742, time: 1.7s\n",
      "\n",
      "🔄 Batch 2/4 (Questions 6-10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: professional_entity_location\n",
      "INFO:__main__:Generating chain for: multimodal_temporal_reasoning\n",
      "INFO:__main__:Generating chain for: causal_mechanism_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q6: professional_entity_... (4 steps, score: 0.820, 0.3s)\n",
      "  ✅ Q7: multimodal_temporal_... (4 steps, score: 0.801, 0.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n",
      "INFO:__main__:Generating chain for: professional_entity_location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q8: causal_mechanism_rea... (4 steps, score: 0.801, 0.4s)\n",
      "  ✅ Q9: methodological_techn... (4 steps, score: 0.740, 0.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n",
      "INFO:__main__:Generating chain for: professional_entity_location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q10: professional_entity_... (4 steps, score: 0.820, 0.3s)\n",
      "  📊 Batch complete: 5/5 success, avg quality: 0.796, time: 1.7s\n",
      "\n",
      "🔄 Batch 3/4 (Questions 11-15)\n",
      "  ✅ Q11: methodological_techn... (4 steps, score: 0.840, 0.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n",
      "INFO:__main__:Generating chain for: professional_entity_location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q12: professional_entity_... (4 steps, score: 0.820, 0.3s)\n",
      "  ✅ Q13: methodological_techn... (4 steps, score: 0.740, 0.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Q14: professional_entity_... (4 steps, score: 0.820, 0.3s)\n",
      "  ✅ Q15: methodological_techn... (4 steps, score: 0.740, 0.3s)\n",
      "  📊 Batch complete: 5/5 success, avg quality: 0.792, time: 1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating chain for: professional_entity_location\n",
      "INFO:__main__:Generating chain for: methodological_technical_reasoning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  💾 Checkpoint saved: output/sci_reason_dataset_checkpoint_batch_3.json\n",
      "\n",
      "🔄 Batch 4/4 (Questions 16-17)\n",
      "  ✅ Q16: professional_entity_... (4 steps, score: 0.820, 0.3s)\n",
      "  ✅ Q17: methodological_techn... (4 steps, score: 0.740, 0.3s)\n",
      "  📊 Batch complete: 2/2 success, avg quality: 0.780, time: 0.7s\n",
      "\n",
      "🎉 PROCESSING COMPLETE!\n",
      "==================================================\n",
      "✅ Successfully processed: 17/17\n",
      "📁 Output saved to: output/sci_reason_dataset.json\n",
      "📊 Average Quality Score: 0.777\n",
      "📏 Average Chain Length: 4.0 steps\n",
      "\n",
      "📋 Results by Reasoning Type:\n",
      "   causal_mechanism_reasoning: 2\n",
      "   cross_subgraph_role_reasoning: 1\n",
      "   methodological_technical_reasoning: 6\n",
      "   multimodal_temporal_reasoning: 2\n",
      "   professional_entity_location: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model cleanup completed\n"
     ]
    }
   ],
   "source": [
    "results, stats = process_dataset_jupyter(\n",
    "    INPUT_FILE, \n",
    "    \"output/sci_reason_dataset.json\",\n",
    "    batch_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "230c517c-e4c9-42f5-8bf6-de9a899421c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_progress(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9caf072-6f49-4940-b594-04dffbb8115e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310_env)",
   "language": "python",
   "name": "py310_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
